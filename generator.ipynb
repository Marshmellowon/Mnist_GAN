{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNjnOV3o1+1eHeeQMXhzZMi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marshmellowon/Mnist_GAN/blob/master/generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSbSngfYPXrx"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras.layers import Flatten, Conv2D, Dense, BatchNormalization, Flatten, LeakyReLU, Dropout, Reshape, Conv2DTranspose\r\n",
        "from tensorflow.keras import Sequential, optimizers, metrics\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import tensorflow_probability as tfp\r\n",
        "ds = tfp.distributions\r\n",
        "\r\n",
        "from functools import reduce"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZS0quO9PdRN"
      },
      "source": [
        "# Load and prepare the MNIST dataset\r\n",
        "mnist = keras.datasets.mnist\r\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n",
        "\r\n",
        "# Split dataset\r\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype(\"float32\") / 255.0\r\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype(\"float32\") / 255.0"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0y1kYYkSuvx",
        "outputId": "654f1ff1-5bf7-4470-b2dd-bd7a6fa8e2da"
      },
      "source": [
        "x_train.shape[0]"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4B-Wwk_TRLR"
      },
      "source": [
        "batch_size = 256\r\n",
        "noise_dim = 100\r\n",
        "lr = 1e-4"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpswq4rkTUtt",
        "outputId": "7c2f09d3-40da-4fe8-a6ed-1b8ae0d852d5"
      },
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices(x_train).shuffle(x_train.shape[0]).batch(batch_size)\r\n",
        "test_data = tf.data.Dataset.from_tensor_slices(x_test).shuffle(x_test.shape[0]).batch(batch_size)\r\n",
        "train_data"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: (None, 28, 28, 1), types: tf.float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EcT7ckCQJHV"
      },
      "source": [
        "generator = Generator(gen_net=gen_net, noise=noise, optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb90-Qb6T810"
      },
      "source": [
        "class GAN(keras.Model):\r\n",
        "\r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        super(GAN, self).__init__()\r\n",
        "        self.__dict__.update(kwargs)\r\n",
        "\r\n",
        "        self.generator = Sequential(self.gen_nn)\r\n",
        "        self.discriminator = Sequential(self.dis_nn)\r\n",
        "        self.cross_entropy = self.cross_entropy\r\n",
        "        self.noise_z = self.noise\r\n",
        "\r\n",
        "    def Generator(self, x):\r\n",
        "        return self.generator(x)\r\n",
        "\r\n",
        "    def Discriminator(self, x):\r\n",
        "        return self.discriminator(x)\r\n",
        "\r\n",
        "    @tf.function\r\n",
        "    def dis_loss(self, real_output, fake_output):\r\n",
        "        # total_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1-fake_output))\r\n",
        "\r\n",
        "        real_loss = self.cross_entropy(tf.ones_like(real_output), real_output)\r\n",
        "        fake_loss = self.cross_entropy(tf.zeros_like(fake_output), fake_output)\r\n",
        "        total_loss = real_loss + fake_loss\r\n",
        "        return total_loss\r\n",
        "    \r\n",
        "    @tf.function\r\n",
        "    def gen_loss(self, fake_output):\r\n",
        "        # loss = -tf.reduce_mean(tf.math.log(fake_output))\r\n",
        "        \r\n",
        "        loss = self.cross_entropy(tf.ones_like(fake_output), fake_output)\r\n",
        "        return loss\r\n",
        "\r\n",
        "        \r\n",
        "    @tf.function\r\n",
        "    def compute_gradient(self, x):\r\n",
        "        noise = self.noise_z\r\n",
        "\r\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\r\n",
        "            generated_img = self.Generator(noise)\r\n",
        "\r\n",
        "            real_output = self.Discriminator(x)\r\n",
        "            fake_output = self.Discriminator(generated_img)\r\n",
        "\r\n",
        "            loss_gen = self.gen_loss(fake_output)\r\n",
        "            loss_dis = self.dis_loss(real_output, fake_output)\r\n",
        "\r\n",
        "        gradient_gen = gen_tape.gradient(loss_gen, self.generator.trainable_variables)\r\n",
        "        gradient_dis = dis_tape.gradient(loss_dis, self.discriminator.trainable_variables)\r\n",
        "\r\n",
        "        return gradient_gen, gradient_dis, loss_gen, loss_dis\r\n",
        "\r\n",
        "    @tf.function\r\n",
        "    def train(self, x):\r\n",
        "        gradient_gen, gradient_dis, loss_gen, loss_dis = self.compute_gradient(x)\r\n",
        "        self.gen_optimizer.apply_gradients(zip(gradient_gen, self.generator.trainable_variables))\r\n",
        "        self.dis_optimizer.apply_gradients(zip(gradient_dis, self.discriminator.trainable_variables))\r\n",
        "        return loss_gen, loss_dis\r\n",
        "\r\n"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NlXwG9UVRtj"
      },
      "source": [
        "gen_nn = [Dense(7*7*256, input_shape=(100,)),\r\n",
        "          BatchNormalization(),\r\n",
        "          LeakyReLU(),\r\n",
        "          \r\n",
        "          Reshape((7,7,256)),\r\n",
        "          Conv2DTranspose(128, (5,5), strides=(1,1), padding='same', use_bias=False),\r\n",
        "          BatchNormalization(),\r\n",
        "          LeakyReLU(),\r\n",
        "          Dropout(0.3),\r\n",
        "          \r\n",
        "          Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', use_bias=False),\r\n",
        "          BatchNormalization(),\r\n",
        "          LeakyReLU(),\r\n",
        "          Dropout(0.3),\r\n",
        "          \r\n",
        "          Conv2DTranspose(1, (5,5), strides=(2,2), padding='same', use_bias=False, activation='tanh')]\r\n",
        "\r\n",
        "dis_nn = [Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]),\r\n",
        "          LeakyReLU(),\r\n",
        "          Dropout(0.3),\r\n",
        "          \r\n",
        "          Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\r\n",
        "          LeakyReLU(),\r\n",
        "          Dropout(0.3),\r\n",
        "          \r\n",
        "          Flatten(),\r\n",
        "          Dense(1)]\r\n",
        "\r\n",
        "optimizer = optimizers.Adam(learning_rate=lr)\r\n",
        "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\r\n",
        "noise = tf.random.normal([batch_size, noise_dim])"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-elDGmxKZiw"
      },
      "source": [
        "gen_network = GAN(gen_nn=gen_nn, \r\n",
        "                  dis_nn=dis_nn, \r\n",
        "                  noise=noise, \r\n",
        "                  gen_optimizer=optimizer, \r\n",
        "                  dis_optimizer=optimizer, \r\n",
        "                  cross_entropy=cross_entropy)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "TKJHKsOjVMqw",
        "outputId": "185b2e87-c6d7-4244-8482-fc1d2723039c"
      },
      "source": [
        "# geerate random noise img\r\n",
        "noise_ = tf.random.normal([1, 100])\r\n",
        "generated_img = gen_network.Generator(noise_)\r\n",
        "plt.imshow(generated_img[0, :, :, 0], cmap='gray')\r\n"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f81feef3f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgogpwJ7N73J",
        "outputId": "6174bcdf-9dcc-41bc-de7b-bbf5b7847038"
      },
      "source": [
        "decision = gen_network.Discriminator(generated_img)\r\n",
        "decision"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.0010838]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuJtxB-LONQH"
      },
      "source": [
        "train_gen_loss = metrics.Mean(name='train_generator_loss')\r\n",
        "train_dis_loss = metrics.Mean(name='train_discriminator_loss')\r\n",
        "test_gen_loss = metrics.Mean(name='test_generator_loss')\r\n",
        "test_dis_loss = metrics.Mean(name='test_discriminator_loss')"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdCwCYfYWuyg",
        "outputId": "58697b87-bdce-49c8-a751-35ad4327cd81"
      },
      "source": [
        "import time\r\n",
        "display_step = 5\r\n",
        "\r\n",
        "strat_time = time.time()\r\n",
        "for epoch in range(50):\r\n",
        "    for x_batch in train_data:\r\n",
        "        gen_loss, dis_loss = gen_network.train(x_batch)\r\n",
        "        train_gen_loss(gen_loss)\r\n",
        "        train_dis_loss(dis_loss)\r\n",
        "\r\n",
        "    for x_batch in test_data:\r\n",
        "        a,b, loss_gen_t, loss_dis_t = gen_network.compute_gradient(x_batch)\r\n",
        "        test_gen_loss(loss_gen_t)\r\n",
        "        test_dis_loss(loss_dis_t)\r\n",
        "\r\n",
        "    print(f'Epoch: {epoch}, Gen[train]: {train_gen_loss.result()}, Dis[train]: {train_dis_loss.result()}, Gen[test]: {test_gen_loss.result()}, Dis[test]: {test_dis_loss.result()} ')\r\n",
        "\r\n",
        "    if epoch % display_step == 0 or epoch == (9):\r\n",
        "        print('display')\r\n",
        "        print(f'time: {time.time() - strat_time} ')\r\n",
        "\r\n",
        "    train_gen_loss.reset_states()\r\n",
        "    train_dis_loss.reset_states()\r\n",
        "    test_gen_loss.reset_states()\r\n",
        "    test_dis_loss.reset_states()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Gen[train]: 1.0945178270339966, Dis[train]: 1.0859788656234741, Gen[test]: 0.6996899843215942, Dis[test]: 1.333933711051941 \n",
            "display\n",
            "time: 10.131375074386597 \n",
            "Epoch: 1, Gen[train]: 0.6989730000495911, Dis[train]: 1.373388648033142, Gen[test]: 0.7684177160263062, Dis[test]: 1.360479712486267 \n",
            "Epoch: 2, Gen[train]: 0.7769612669944763, Dis[train]: 1.2817269563674927, Gen[test]: 0.7335605025291443, Dis[test]: 1.2394635677337646 \n",
            "Epoch: 3, Gen[train]: 0.7679622769355774, Dis[train]: 1.2709323167800903, Gen[test]: 0.775357723236084, Dis[test]: 1.3576656579971313 \n",
            "Epoch: 4, Gen[train]: 0.8273834586143494, Dis[train]: 1.2160924673080444, Gen[test]: 0.6772657036781311, Dis[test]: 1.293562412261963 \n",
            "Epoch: 5, Gen[train]: 0.8960031270980835, Dis[train]: 1.1121132373809814, Gen[test]: 0.9056054353713989, Dis[test]: 1.0671296119689941 \n",
            "display\n",
            "time: 45.39218473434448 \n",
            "Epoch: 6, Gen[train]: 0.9781966805458069, Dis[train]: 1.0200294256210327, Gen[test]: 0.8932216763496399, Dis[test]: 1.1012732982635498 \n",
            "Epoch: 7, Gen[train]: 1.1624716520309448, Dis[train]: 0.8552316427230835, Gen[test]: 1.7110679149627686, Dis[test]: 0.5917720198631287 \n",
            "Epoch: 8, Gen[train]: 1.4391931295394897, Dis[train]: 0.6608118414878845, Gen[test]: 1.3455047607421875, Dis[test]: 0.7311056852340698 \n",
            "Epoch: 9, Gen[train]: 1.464641809463501, Dis[train]: 0.6347813606262207, Gen[test]: 1.7442973852157593, Dis[test]: 0.5261707305908203 \n",
            "display\n",
            "time: 73.47841477394104 \n",
            "Epoch: 10, Gen[train]: 1.58536958694458, Dis[train]: 0.5542274117469788, Gen[test]: 1.3355939388275146, Dis[test]: 0.666961669921875 \n",
            "display\n",
            "time: 80.4987301826477 \n",
            "Epoch: 11, Gen[train]: 1.6925170421600342, Dis[train]: 0.5414078235626221, Gen[test]: 1.6654367446899414, Dis[test]: 0.5183637142181396 \n",
            "Epoch: 12, Gen[train]: 1.6384772062301636, Dis[train]: 0.5678629875183105, Gen[test]: 1.658982515335083, Dis[test]: 0.5766053795814514 \n",
            "Epoch: 13, Gen[train]: 1.535971760749817, Dis[train]: 0.6254962682723999, Gen[test]: 1.3272831439971924, Dis[test]: 0.6729170083999634 \n",
            "Epoch: 14, Gen[train]: 1.5232661962509155, Dis[train]: 0.6297881603240967, Gen[test]: 1.5630652904510498, Dis[test]: 0.6184026598930359 \n",
            "Epoch: 15, Gen[train]: 1.5279145240783691, Dis[train]: 0.6290417313575745, Gen[test]: 1.2166248559951782, Dis[test]: 0.6586916446685791 \n",
            "display\n",
            "time: 115.58713102340698 \n",
            "Epoch: 16, Gen[train]: 1.494388461112976, Dis[train]: 0.6421682238578796, Gen[test]: 1.4677999019622803, Dis[test]: 0.6703260540962219 \n",
            "Epoch: 17, Gen[train]: 1.4964218139648438, Dis[train]: 0.6451730132102966, Gen[test]: 1.3784972429275513, Dis[test]: 0.6607884168624878 \n",
            "Epoch: 18, Gen[train]: 1.4898085594177246, Dis[train]: 0.6460648775100708, Gen[test]: 1.5853455066680908, Dis[test]: 0.6399347186088562 \n",
            "Epoch: 19, Gen[train]: 1.444744348526001, Dis[train]: 0.6751027703285217, Gen[test]: 1.4534999132156372, Dis[test]: 0.7056652903556824 \n",
            "Epoch: 20, Gen[train]: 1.3939220905303955, Dis[train]: 0.7042838335037231, Gen[test]: 1.4806716442108154, Dis[test]: 0.6362877488136292 \n",
            "display\n",
            "time: 150.6886270046234 \n",
            "Epoch: 21, Gen[train]: 1.371127724647522, Dis[train]: 0.7218106985092163, Gen[test]: 1.2331202030181885, Dis[test]: 0.7599136829376221 \n",
            "Epoch: 22, Gen[train]: 1.3501917123794556, Dis[train]: 0.7360615730285645, Gen[test]: 1.4765050411224365, Dis[test]: 0.7676782011985779 \n",
            "Epoch: 23, Gen[train]: 1.3507181406021118, Dis[train]: 0.7426642775535583, Gen[test]: 1.1825029850006104, Dis[test]: 0.7814924716949463 \n",
            "Epoch: 24, Gen[train]: 1.3211514949798584, Dis[train]: 0.7762673497200012, Gen[test]: 1.0549854040145874, Dis[test]: 0.8004552721977234 \n",
            "Epoch: 25, Gen[train]: 1.3146737813949585, Dis[train]: 0.7793868184089661, Gen[test]: 1.5842255353927612, Dis[test]: 0.7349728345870972 \n",
            "display\n",
            "time: 185.9032506942749 \n",
            "Epoch: 26, Gen[train]: 1.3160216808319092, Dis[train]: 0.7744854688644409, Gen[test]: 1.5631825923919678, Dis[test]: 0.769949197769165 \n",
            "Epoch: 27, Gen[train]: 1.279739499092102, Dis[train]: 0.8041386604309082, Gen[test]: 1.116099238395691, Dis[test]: 0.8212300539016724 \n",
            "Epoch: 28, Gen[train]: 1.2551835775375366, Dis[train]: 0.8165575861930847, Gen[test]: 1.5815470218658447, Dis[test]: 0.8363280296325684 \n",
            "Epoch: 29, Gen[train]: 1.2563773393630981, Dis[train]: 0.8191206455230713, Gen[test]: 1.355872392654419, Dis[test]: 0.7215363383293152 \n",
            "Epoch: 30, Gen[train]: 1.2431139945983887, Dis[train]: 0.8185338973999023, Gen[test]: 1.0858880281448364, Dis[test]: 0.8584868311882019 \n",
            "display\n",
            "time: 221.19344019889832 \n",
            "Epoch: 31, Gen[train]: 1.2528629302978516, Dis[train]: 0.814653217792511, Gen[test]: 1.117326021194458, Dis[test]: 0.7690194845199585 \n",
            "Epoch: 32, Gen[train]: 1.2151710987091064, Dis[train]: 0.8493111729621887, Gen[test]: 1.0755704641342163, Dis[test]: 0.8865777850151062 \n",
            "Epoch: 33, Gen[train]: 1.2138657569885254, Dis[train]: 0.8376249074935913, Gen[test]: 1.1711463928222656, Dis[test]: 0.8674243688583374 \n",
            "Epoch: 34, Gen[train]: 1.1929214000701904, Dis[train]: 0.8556938171386719, Gen[test]: 0.885380744934082, Dis[test]: 0.9125350117683411 \n",
            "Epoch: 35, Gen[train]: 1.2016427516937256, Dis[train]: 0.8564357161521912, Gen[test]: 1.3180845975875854, Dis[test]: 0.8866850137710571 \n",
            "display\n",
            "time: 256.38787841796875 \n",
            "Epoch: 36, Gen[train]: 1.2039450407028198, Dis[train]: 0.8444205522537231, Gen[test]: 1.2085646390914917, Dis[test]: 0.8596501350402832 \n",
            "Epoch: 37, Gen[train]: 1.1814676523208618, Dis[train]: 0.8650387525558472, Gen[test]: 1.1252644062042236, Dis[test]: 0.9145034551620483 \n",
            "Epoch: 38, Gen[train]: 1.177563190460205, Dis[train]: 0.8699986934661865, Gen[test]: 1.2533254623413086, Dis[test]: 0.9058161973953247 \n",
            "Epoch: 39, Gen[train]: 1.1899089813232422, Dis[train]: 0.8666325211524963, Gen[test]: 1.3267109394073486, Dis[test]: 0.8613032102584839 \n",
            "Epoch: 40, Gen[train]: 1.1908658742904663, Dis[train]: 0.854333221912384, Gen[test]: 1.313800573348999, Dis[test]: 0.7962538599967957 \n",
            "display\n",
            "time: 291.4340932369232 \n",
            "Epoch: 41, Gen[train]: 1.1740761995315552, Dis[train]: 0.8761136531829834, Gen[test]: 1.4062583446502686, Dis[test]: 0.906038761138916 \n",
            "Epoch: 42, Gen[train]: 1.1827163696289062, Dis[train]: 0.873738169670105, Gen[test]: 1.5714833736419678, Dis[test]: 0.8607041239738464 \n",
            "Epoch: 43, Gen[train]: 1.1812251806259155, Dis[train]: 0.8807508945465088, Gen[test]: 1.085384726524353, Dis[test]: 0.8740989565849304 \n",
            "Epoch: 44, Gen[train]: 1.1703147888183594, Dis[train]: 0.8832266330718994, Gen[test]: 1.2259457111358643, Dis[test]: 0.9542790651321411 \n",
            "Epoch: 45, Gen[train]: 1.1613634824752808, Dis[train]: 0.890659749507904, Gen[test]: 1.1568872928619385, Dis[test]: 0.9246540069580078 \n",
            "display\n",
            "time: 326.488121509552 \n",
            "Epoch: 46, Gen[train]: 1.165148138999939, Dis[train]: 0.8955085873603821, Gen[test]: 1.5125534534454346, Dis[test]: 0.986284613609314 \n",
            "Epoch: 47, Gen[train]: 1.1509720087051392, Dis[train]: 0.8962638974189758, Gen[test]: 1.0182037353515625, Dis[test]: 0.924778163433075 \n",
            "Epoch: 48, Gen[train]: 1.1466095447540283, Dis[train]: 0.90472412109375, Gen[test]: 1.141187071800232, Dis[test]: 0.9218486547470093 \n",
            "Epoch: 49, Gen[train]: 1.1553844213485718, Dis[train]: 0.9010291695594788, Gen[test]: 1.009199857711792, Dis[test]: 0.7555568218231201 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}